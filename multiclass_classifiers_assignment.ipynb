{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iD1KjC8-hl_P"
   },
   "source": [
    "# Multiclass Classifiers\n",
    "In this assignment you will load a dataset and train two models to perform multiclass classification and compare the results of the models. The dataset is the **digits** dataset available from the sklearn's *datasets* library. This dataset contain 1797 samples of written digits. The goal is to correctly identify digits from 0 to 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sZYeUk8FjHsd"
   },
   "source": [
    "## Load the data\n",
    "\n",
    "1. import the *load_digits* function from the *sklearn.datasets* library\n",
    "2. invoke *load_digits* with the *return_X_y* parameter set to true and store the returned dataset in variable **X** and **y**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yU07T75-he8U"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "X, y = load_digits(return_X_y = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "isPHrCpCj5lL"
   },
   "source": [
    "## Exploratory Data Analysis\n",
    "Perform a few exploratory  steps including:\n",
    "\n",
    "1. Display the number of rows of data returned\n",
    "2. Display the number of features in the dataset\n",
    "3. Use Numpy's **bincount** to display how many samples belong to each class. Is this a balanced dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EX7gj8IGkTu7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows in the dataset is 1797\n",
      "The number of features in the dataset is 64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([178, 182, 177, 183, 181, 182, 181, 179, 174, 180])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "print('The number of rows in the dataset is {:d}'.format(X.shape[0]))\n",
    "print('The number of features in the dataset is {:d}'.format(X.shape[1]))\n",
    "np.bincount(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6AdSZLoalPDO"
   },
   "source": [
    "## Prepare training and testing data\n",
    "1. Use *train_test_split* to split the dataset into a training set and a test set. Set the proportion of test data to 20%. Set a random state value so that the results will be repeatable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K8oYDSclmIRw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y , test_size = .2, random_state = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "of-cq2s0mdx6"
   },
   "source": [
    "## Cross validation with Logistic Regression\n",
    "In this step you will create a LogisticRegression classifier and use 5-fold cross validation to train the model.\n",
    "\n",
    "1. import *LogisticRegression* classifier from sklearn\n",
    "2. instantiate a LogisticRegression classifier with the 'lbfgs' solver and 'ovr' multiclass strategy. You may have to set the maximum number of iterations to 1000.\n",
    "3. perform cross validation on the model\n",
    "4. print the cross validation scores and the mean of the cross validation scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UMdjcXaplne9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for the 5 folds:  [0.94736842 0.97297297 0.95833333 0.89855072 0.92753623]\n",
      "Mean cross validation score: 0.941\n",
      "Process Time = 13.08 seconds\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "time1= time.process_time()\n",
    "\n",
    "lr_clf = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter = 10000)\n",
    "lr_clf.fit(X_train,y_train)\n",
    "\n",
    "lr_cv_scores = cross_val_score(lr_clf, X_test, y_test, cv = 5)\n",
    "\n",
    "time2 = time.process_time()\n",
    "\n",
    "print('Accuracy scores for the 5 folds: ', lr_cv_scores)\n",
    "print('Mean cross validation score: {:.3f}'.format(lr_cv_scores.mean()))\n",
    "print('Process Time = {:.2f}'.format(time2-time1), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PcZHs1vYoRBN"
   },
   "source": [
    "## Cross validation with RandomForest\n",
    "Perform the same steps as above but this time with a RandomForestClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pCD2ROdToySP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy scores for the 5 folds:  [0.88157895 0.90540541 0.95833333 0.85507246 0.91304348]\n",
      "Mean cross validation score: 0.903\n",
      "Process Time = 0.58 seconds\n"
     ]
    }
   ],
   "source": [
    "# imports here\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "time1= time.process_time()\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=24)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "rf_cv_scores = cross_val_score(rf_clf, X_test , y_test , cv = 5)\n",
    "\n",
    "time2 = time.process_time()\n",
    "\n",
    "print('Accuracy scores for the 5 folds: ', rf_cv_scores)\n",
    "print('Mean cross validation score: {:.3f}'.format(rf_cv_scores.mean()))\n",
    "print('Process Time = {:.2f}'.format(time2-time1), 'seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is higher for the logistic regression model. However, the random forest model runs approximately 20 times faster for this dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of multiclass classifiers assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
