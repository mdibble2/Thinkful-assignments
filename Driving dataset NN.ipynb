{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as olt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Challenge Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Data Set Information:\n",
    "\n",
    "Features are extracted from electric current drive signals. The drive has intact and defective components. This results in 11 different classes with different conditions. Each condition has been measured several times by 12 different operating conditions, this means by different speeds, load moments and load forces. The current signals are measured with a current probe and an oscilloscope on two phases.\n",
    "\n",
    "From UCI machine learning database: https://archive.ics.uci.edu/ml/datasets/Dataset+for+Sensorless+Drive+Diagnosis#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature1</th>\n",
       "      <th>Feature2</th>\n",
       "      <th>Feature3</th>\n",
       "      <th>Feature4</th>\n",
       "      <th>Feature5</th>\n",
       "      <th>Feature6</th>\n",
       "      <th>Feature7</th>\n",
       "      <th>Feature8</th>\n",
       "      <th>Feature9</th>\n",
       "      <th>Feature10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature40</th>\n",
       "      <th>Feature41</th>\n",
       "      <th>Feature42</th>\n",
       "      <th>Feature43</th>\n",
       "      <th>Feature44</th>\n",
       "      <th>Feature45</th>\n",
       "      <th>Feature46</th>\n",
       "      <th>Feature47</th>\n",
       "      <th>Feature48</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>-3.014600e-07</td>\n",
       "      <td>8.260300e-06</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-1.438600e-06</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.031718</td>\n",
       "      <td>0.031710</td>\n",
       "      <td>0.031721</td>\n",
       "      <td>-0.032963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63308</td>\n",
       "      <td>2.9646</td>\n",
       "      <td>8.1198</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4961</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>-1.4996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.913200e-06</td>\n",
       "      <td>-5.247700e-06</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>2.778900e-06</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.030810</td>\n",
       "      <td>0.030806</td>\n",
       "      <td>-0.033520</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.59314</td>\n",
       "      <td>7.6252</td>\n",
       "      <td>6.1690</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.4967</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>-1.5005</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>-2.951700e-06</td>\n",
       "      <td>-3.184000e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000001</td>\n",
       "      <td>-1.575300e-06</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.032877</td>\n",
       "      <td>0.032880</td>\n",
       "      <td>0.032896</td>\n",
       "      <td>-0.029834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63252</td>\n",
       "      <td>2.7784</td>\n",
       "      <td>5.3017</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4983</td>\n",
       "      <td>-1.4982</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>-1.4985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-1.322600e-06</td>\n",
       "      <td>8.820100e-06</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-7.282900e-07</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.029410</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.029417</td>\n",
       "      <td>-0.030156</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.62289</td>\n",
       "      <td>6.5534</td>\n",
       "      <td>6.2606</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4963</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4975</td>\n",
       "      <td>-1.4976</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>-6.836600e-08</td>\n",
       "      <td>5.666300e-07</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-7.940600e-07</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030119</td>\n",
       "      <td>0.030145</td>\n",
       "      <td>-0.031393</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.63010</td>\n",
       "      <td>4.5155</td>\n",
       "      <td>9.5231</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4958</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>-1.4959</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Feature1      Feature2  Feature3  Feature4      Feature5  Feature6  \\\n",
       "0 -3.014600e-07  8.260300e-06 -0.000012 -0.000002 -1.438600e-06 -0.000021   \n",
       "1  2.913200e-06 -5.247700e-06  0.000003 -0.000006  2.778900e-06 -0.000004   \n",
       "2 -2.951700e-06 -3.184000e-06 -0.000016 -0.000001 -1.575300e-06  0.000017   \n",
       "3 -1.322600e-06  8.820100e-06 -0.000016 -0.000005 -7.282900e-07  0.000004   \n",
       "4 -6.836600e-08  5.666300e-07 -0.000026 -0.000006 -7.940600e-07  0.000013   \n",
       "\n",
       "   Feature7  Feature8  Feature9  Feature10  ...  Feature40  Feature41  \\\n",
       "0  0.031718  0.031710  0.031721  -0.032963  ...   -0.63308     2.9646   \n",
       "1  0.030804  0.030810  0.030806  -0.033520  ...   -0.59314     7.6252   \n",
       "2  0.032877  0.032880  0.032896  -0.029834  ...   -0.63252     2.7784   \n",
       "3  0.029410  0.029401  0.029417  -0.030156  ...   -0.62289     6.5534   \n",
       "4  0.030119  0.030119  0.030145  -0.031393  ...   -0.63010     4.5155   \n",
       "\n",
       "   Feature42  Feature43  Feature44  Feature45  Feature46  Feature47  \\\n",
       "0     8.1198    -1.4961    -1.4961    -1.4961    -1.4996    -1.4996   \n",
       "1     6.1690    -1.4967    -1.4967    -1.4967    -1.5005    -1.5005   \n",
       "2     5.3017    -1.4983    -1.4983    -1.4982    -1.4985    -1.4985   \n",
       "3     6.2606    -1.4963    -1.4963    -1.4963    -1.4975    -1.4975   \n",
       "4     9.5231    -1.4958    -1.4958    -1.4958    -1.4959    -1.4959   \n",
       "\n",
       "   Feature48  label  \n",
       "0    -1.4996      1  \n",
       "1    -1.5005      1  \n",
       "2    -1.4985      1  \n",
       "3    -1.4976      1  \n",
       "4    -1.4959      1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#generating the table column names\n",
    "Feature_columnnnames=[]\n",
    "for i in range(48):\n",
    "    Feature_columnnnames.append(\"Feature\"+str(i+1))\n",
    "Feature_columnnnames.append(\"label\")\n",
    "\n",
    "data = pd.read_csv('Sensorless_drive_diagnosis.txt', sep=\" \", header=None,names=Feature_columnnnames)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58509, 49)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum().sum() #calc total number of nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split into test and train\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop('label',axis=1)\n",
    "Y = data.label\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,shuffle= True,test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the model\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Establish and fit the model\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,),max_iter=500) #start with default, 1 layer with 100 perceptrons\n",
    "mlp.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9533837443862997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megandibble/opt/anaconda3/lib/python3.7/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8982957383913787\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(mlp,X_train,y_train,cv=3).mean())\n",
    "print(cross_val_score(mlp,X_test,y_test,cv=3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pretty good for a first try, model is only slightly overfitting. I will try to tune the number of layers and number of perceptrons. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(100, 100), learning_rate='constant',\n",
       "              learning_rate_init=0.001, max_iter=500, momentum=0.9,\n",
       "              n_iter_no_change=10, nesterovs_momentum=True, power_t=0.5,\n",
       "              random_state=None, shuffle=True, solver='adam', tol=0.0001,\n",
       "              validation_fraction=0.1, verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#increasing the number of layers, keep number of perceptrons the same\n",
    "mlp2 = MLPClassifier(hidden_layer_sizes=(100,100),max_iter=500)\n",
    "mlp2.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9663740729067914\n",
      "0.8954849719966562\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(mlp2,X_train,y_train,cv=3).mean())\n",
    "print(cross_val_score(mlp2,X_test,y_test,cv=3).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.866863585785958"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try increasing number of neurons in layer\n",
    "mlp3 = MLPClassifier(hidden_layer_sizes=(1000,),max_iter=500)\n",
    "mlp3.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9438356525197803\n",
      "0.8830991514078956\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(mlp3,X_train,y_train,cv=3).mean())\n",
    "print(cross_val_score(mlp3,X_test,y_test,cv=3).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8993290030187239"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#try two smaller layers\n",
    "mlp4 = MLPClassifier(hidden_layer_sizes=(50,50),max_iter=500)\n",
    "mlp4.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9536001479744888\n",
      "0.8916288952317616\n"
     ]
    }
   ],
   "source": [
    "print(cross_val_score(mlp4,X_train,y_train,cv=3).mean())\n",
    "print(cross_val_score(mlp4,X_test,y_test,cv=3).mean())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Best model was mlp #2 with 2 layers, 100 perceptrons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a random forest model to compare classification scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/megandibble/opt/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9923950081752876"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier().fit(X_train,y_train)\n",
    "\n",
    "cross_val_score(rf,X_test,y_test,cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9978206998176326"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(rf,X_train,y_train,cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest outperformed the neural networks--there is no need to use a neural network on this data when a more interpretable and less complex method gives a better score. Even though there is a lot of data in this dataset, it is not complex data (like images) and thus does not really merit using an ANN model. I did not realize this when I was picking the dataset originally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
